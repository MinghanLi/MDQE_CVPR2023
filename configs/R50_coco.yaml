MODEL:
  META_ARCHITECTURE: "MDQE"
  WEIGHTS: "detectron2://ImageNetPretrained/torchvision/R-50.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res3", "res4", "res5"]
  MDQE:
    NUM_OBJECT_QUERIES: 200
    ENC_LAYERS: 6
    DEC_LAYERS: 6
    ENC_NUM_POINTS: 4
    DEC_NUM_POINTS: 4
    NUM_FEATURE_LEVELS: 4
    DEC_TEMPORAL: True
    HIDDEN_DIM: 256
    NUM_CLASSES: 80
    WINDOW_CLIPASS: 5
    TRACK_EMBED_DIM: 64
DATASETS:
  TRAIN: ("coco_2017_train",)
  TEST: ("coco_2017_val",)
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.0001
  STEPS: (236000,)
  MAX_ITER: 267000  # 3x training
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.05
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: False  # Enable automatic mixed precision for training
INPUT:
  FORMAT: "RGB"
  SAMPLING_FRAME_NUM: 1
  AUGMENTATIONS: []
  RANDOM_FLIP: "flip_by_clip"
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  MIN_SIZE_TRAIN: (320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672) #, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: [384, 600]
TEST:
  EVAL_PERIOD: 5000
  DETECTIONS_PER_IMAGE: 100
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
VERSION: 2
OUTPUT_DIR: output/coco/mdqe_r50_coco_bs16_3x_f1/
